{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ImagineDogs/TranstornosMentais/main/dados/df_cid10.csv')\n",
    "table = df[['cid10_faixa', 'cid10_faixa_alta', 'cid10_seg_faixa']].loc[~df['cid10_faixa'].isnull()]\n",
    "table = table.fillna('Sem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para da inicio as predições é necessário utilizar um encoder adequado para os dados, por se tratarem de categorias independentes, ou seja, não possuem ordem, será utilizaro o OneHotEncoder que transforma cada categoria em uma coluna de valores binarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "encX = OneHotEncoder()\n",
    "ency = OneHotEncoder()\n",
    "\n",
    "X = table[['cid10_faixa', 'cid10_seg_faixa']]\n",
    "X = encX.fit_transform(X)\n",
    "y = np.array(table['cid10_faixa_alta'])\n",
    "# y = ency.fit_transform(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer análises mais profundas de configurações podemos separar nossos dados em  treino, teste e validação, porém neste primeiro momento vamos utilizar apenas treino e teste por se tratar de uma abordagem mais simplista inicialmente. Contúdo uma função para as três separações já pode ser mantida pronta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(X, y, test_size=None, val_size = None,random_state=None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=random_state)\n",
    "    \n",
    "    return X_train.toarray(), X_test.toarray(), X_val.toarray(), y_train, y_test, y_val\n",
    "\n",
    "# X_train, X_test, X_val, y_train, y_test, y_val = train_test_val_split(X, y, test_size=0.2, val_size = 0.05,random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, = X_train.toarray(), X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6574, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6574,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['F10-F19', 'F10-F19', 'F20-F29', ..., 'F10-F19', 'F30-F39',\n",
       "       'F30-F39'], dtype=object)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão utilizados modelos explicativos em um primeiro momento para mantermos a explicabilidade das predições.\n",
    "\n",
    "Os dois modelos escolhidos foram NaiveBayes e DecisionTree por serem algoritmos básicos porém eficazes.\n",
    "\n",
    "Será utilizado também um modelo baseline para comparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação dos modelos\n",
    "def evaluate(y_pred, y_test):\n",
    "    acuracia = accuracy_score(y_pred, y_test)\n",
    "    f1 = f1_score(y_pred, y_test, average='weighted')\n",
    "\n",
    "    print('Resultados:')\n",
    "    print(f'    Acuracia: {acuracia}')\n",
    "    print(f'    F1: {f1}')\n",
    "    return acuracia, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados:\n",
      "    Acuracia: 0.37165450121654503\n",
      "    F1: 0.5419068736141907\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dummy.predict(X_test)\n",
    "acuracia_dummy, f1_dummy = evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados:\n",
      "    Acuracia: 0.7390510948905109\n",
      "    F1: 0.7488247891294786\n"
     ]
    }
   ],
   "source": [
    "nb = CategoricalNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "acuracia_nb, f1_nb = evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a Árvore de Decisão será utilizado GridSearch para encontrar os melhores parâmetros dentro de um escopo que pode ser escolhido.\n",
    "\n",
    "Vale lembrar que GridSearch testa cada combinação de parâmetros passados em um K-Fold Cross Validation, utilizando a combinação que melhor desempenhar.\n",
    "Neste caso serão 5 folds com a métrica F1 balanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 7, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "tc = DecisionTreeClassifier(random_state=42)\n",
    "param_tc = {'criterion': ['gini', 'entropy', 'log_loss'], 'splitter': ['best', 'random'], 'max_depth': range(5, 20, 1)}\n",
    "\n",
    "\n",
    "gs_tc = GridSearchCV(tc, param_tc, cv=5, scoring='f1_weighted')\n",
    "\n",
    "\n",
    "best_model = gs_tc.fit(X_train, y_train)\n",
    "print(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iris_tree.pdf'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerador de imagem pra a árvore\n",
    "\n",
    "# Definindo os labels das features\n",
    "model = DecisionTreeClassifier(random_state=42, criterion=best_model.best_params_['criterion'], max_depth=best_model.best_params_['max_depth'], splitter=best_model.best_params_['splitter'])\n",
    "model.fit(X_train, y_train)\n",
    "df2 = pd.DataFrame(encX.inverse_transform(X_train), columns=['cid10_faixa', 'cid10_seg_faixa'])\n",
    "labels = df2['cid10_faixa'].apply(lambda x: 'cid10_faixa_' + x).unique().tolist()\n",
    "labels.extend(df2['cid10_seg_faixa'].apply(lambda x: 'cid10_seg_faixa_' + x).unique().tolist())\n",
    "labels\n",
    "\n",
    "#Gerando o gráfico\n",
    "dot_data = export_graphviz(model, out_file=None, \n",
    "                           feature_names=labels,  \n",
    "                           class_names=np.unique(y_train).tolist(),  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)  \n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados:\n",
      "    Acuracia: 0.7402676399026764\n",
      "    F1: 0.7511145511008342\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "acuracia_dt, f1_dt = evaluate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaiveBayes</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acuracia</th>\n",
       "      <td>0.739051</td>\n",
       "      <td>0.740268</td>\n",
       "      <td>0.371655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Balanceado</th>\n",
       "      <td>0.748825</td>\n",
       "      <td>0.751115</td>\n",
       "      <td>0.541907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NaiveBayes  DecisionTree     Dummy\n",
       "Acuracia         0.739051      0.740268  0.371655\n",
       "F1 Balanceado    0.748825      0.751115  0.541907"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = pd.DataFrame()\n",
    "resultados['NaiveBayes'] = pd.Series([acuracia_nb, f1_nb])\n",
    "resultados['DecisionTree'] = pd.Series([acuracia_dt, f1_dt])\n",
    "resultados['Dummy'] = pd.Series([acuracia_dummy, f1_dummy])\n",
    "resultados.index = ['Acuracia', 'F1 Balanceado']\n",
    "resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
